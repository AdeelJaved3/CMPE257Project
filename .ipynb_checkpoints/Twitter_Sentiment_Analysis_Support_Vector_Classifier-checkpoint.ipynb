{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwdbTJ_ZIw7y"
   },
   "source": [
    "# Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwA9OqE1IY53"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1O1Bg_pI1VD"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Galut_WrI4bV"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
    "\n",
    "# test data\n",
    "test = pd.read_csv(\"./content/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvtCODUEJciM"
   },
   "source": [
    "# Data Exploration (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Mni8YItfJcSs",
    "outputId": "c880fcf3-9269-450b-ad39-c3a4af89bf88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lRex8owXJV40",
    "outputId": "a878a1d5-58e2-4578-cb46-167ee6a2e74f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "17192  49155  thought factory: left-right polarisation! #tru...\n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
       "17195  49158  happy, at work conference: right mindset leads...\n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jAUIxDOYJmvt",
    "outputId": "a385b811-8a70-4eeb-f33f-037a723040a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29720"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-racist/sexist related tweets\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ijAyVcYjKPc_",
    "outputId": "6def6736-d9f5-4853-faa0-26451a3af937"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# racist/sexist related tweets\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mubp2OU0M2-M",
    "outputId": "e2b3fe4e-abc5-4ebb-9354-6e6d520c2f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any missing values\n",
    "train.isnull().sum()\n",
    "#train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9uidliWUL9t"
   },
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "G9BW8zWhKWbn",
    "outputId": "238f5172-e76a-4959-d511-90f7fb247a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "#install tweet-preprocessor to clean tweets\n",
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iB47T9w3YNry"
   },
   "outputs": [],
   "source": [
    "# remove special characters using the regular expression library\n",
    "import re\n",
    "\n",
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Kaf60xXPryT"
   },
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "\n",
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5BFI2HEUm6W"
   },
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "suq-CJYUXAT8",
    "outputId": "6379536e-345b-4887-9773-dd50708fc52c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for credit i cant use cause they dont o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>2 2 huge fan fare and big talking before they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won love the land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here  im its so</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  when a father is dysfunctional and is so selfi...  \n",
       "1  thanks for credit i cant use cause they dont o...  \n",
       "2                                bihday your majesty  \n",
       "3            i love u take with u all the time in ur  \n",
       "4                             factsguide society now  \n",
       "5  2 2 huge fan fare and big talking before they ...  \n",
       "6                             camping tomorrow danny  \n",
       "7  the next school year is the year for exams can...  \n",
       "8                               we won love the land  \n",
       "9                           welcome here  im its so   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0_dHhhn2bHYL",
    "outputId": "a0690808-0cd6-4bc0-fde6-8c362af280a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory left right polarisation &amp;gt3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>today in omg &amp;amp used words like assets&amp;ampli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song so glad free download</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "17192  49155  thought factory: left-right polarisation! #tru...   \n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...   \n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "17195  49158  happy, at work conference: right mindset leads...   \n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "17192       thought factory left right polarisation &gt3  \n",
       "17193                             feeling like a mermaid  \n",
       "17194  today in omg &amp used words like assets&ampli...  \n",
       "17195  happy at work conference right mindset leads t...  \n",
       "17196                      my song so glad free download  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the test data and append the cleaned tweets to the test data\n",
    "test_tweet = clean_tweets(test[\"tweet\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pycld2\n",
    "\n",
    "def sample_encode(df):\n",
    "\n",
    "    df = df.loc[df['tweet_text'].apply(lambda x: safe_detect(x) == 'en')]\n",
    "\n",
    "    # Sample 3,740 observation for each category\n",
    "    sample_religion = df.loc[df['cyberbullying_type']=='religion'].sample\\\n",
    "        (n=3450, random_state=42)\n",
    "\n",
    "    sample_age = df.loc[df['cyberbullying_type']=='age'].sample\\\n",
    "        (n=3450, random_state=42)\n",
    "\n",
    "    sample_other_cyberbullying = df.loc[df['cyberbullying_type']=='other_cyberbullying'].sample\\\n",
    "        (n=3450, random_state=42)\n",
    "\n",
    "    sample_ethnicity = df.loc[df['cyberbullying_type']=='ethnicity'].sample\\\n",
    "        (n=3450, random_state=42)\n",
    "\n",
    "    sample_gender = df.loc[df['cyberbullying_type']=='gender'].sample\\\n",
    "        (n=3450, random_state=42)\n",
    "\n",
    "    samples_df = pd.concat([sample_religion,sample_age,\n",
    "                            sample_other_cyberbullying,sample_ethnicity,sample_gender])\n",
    "\n",
    "    # Manually encode the different types of cyberbullying/non-cyberbullying\n",
    "    samples_df.loc[:, 'cyberbullying_type'] = 1\n",
    "\n",
    "    df.loc[df['cyberbullying_type'] == 'not_cyberbullying', 'cyberbullying_type'] = 0\n",
    "    non_cyberbullying_df = df.loc[df['cyberbullying_type']==0].copy()\n",
    "\n",
    "    # Ensure target column is of type int\n",
    "    non_cyberbullying_df['cyberbullying_type'] = non_cyberbullying_df['cyberbullying_type']\\\n",
    "        .astype(int)\n",
    "    samples_df['cyberbullying_type'] = samples_df['cyberbullying_type'].astype(int)\n",
    "\n",
    "    df = pd.concat([non_cyberbullying_df,samples_df])\n",
    "\n",
    "    # Check Unique y values\n",
    "    y_values = df['cyberbullying_type'].value_counts()\n",
    "    print(f'Check y values and counts \\n {y_values}')\n",
    "\n",
    "    return df\n",
    "\n",
    "###Intergrated code from project\n",
    "def safe_detect(text):\n",
    "    try:\n",
    "        return pycld2.detect(text)[2][0][1]\n",
    "    except Exception:\n",
    "        return 'unknown'\n",
    "\n",
    "def load_pkl_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    # Check for missing values\n",
    "    missing_values = df.isna().sum()\n",
    "    print(f'Missing Values:\\n{missing_values}')\n",
    "\n",
    "    # Find all tweets that are less than 3 words and remove them\n",
    "    df['tweet_length'] = [len(text.split()) for text in df.tweet_text]\n",
    "    df = df.loc[df['tweet_length'] >= 3]\n",
    "    df.drop('tweet_length', axis=1, inplace=True)\n",
    "\n",
    "    # Clean the text by removing special characters and converting all text to lower case\n",
    "    df['tweet_text'] = df['tweet_text'].apply(clean_tweets)\n",
    "\n",
    "    return df\n",
    "\n",
    "def driver():\n",
    "    data = load_pkl_data('./data 2/formspring_data.pkl')\n",
    "    formspring_df = pd.DataFrame(data)\n",
    "\n",
    "    # Check the raw formspring data\n",
    "    print(f'Check raw formspring_df: {formspring_df.head(5)}')\n",
    "    formspring_df.rename(columns={'text':'tweet_text', 'label':\n",
    "        'cyberbullying_type'}, inplace=True)\n",
    "    formspring_df = preprocess_data(formspring_df)\n",
    "\n",
    "    # Remove any non english entries\n",
    "    formspring_df = formspring_df.loc[formspring_df['tweet_text'].apply(lambda x: safe_detect(x) == 'en')]\n",
    "\n",
    "    # Check cleaned formspring data\n",
    "    print(f'Check cleaned formspring_df: {formspring_df.head(5)}')\n",
    "\n",
    "    df = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
    "\n",
    "    # Check raw cyberbullying tweet data\n",
    "    print(f'Check raw cyberbullying tweet data: {df.head(5)}')\n",
    "\n",
    "    df = preprocess_data(df)\n",
    "\n",
    "    # Check cleaned cyberbullying tweet data\n",
    "    print(f'Check cleaned cyberbullying tweet data: {df.head(5)}')\n",
    "    df = sample_encode(df)\n",
    "\n",
    "    # Merge both dataframes for data balancing\n",
    "    merged_df = pd.concat([df, formspring_df])\n",
    "\n",
    "    # Check merged dataframe data\n",
    "    # print(f'Check merged dataframe {merged_df.head(10)}')\n",
    "    count_cyberbullying = len(merged_df[merged_df['cyberbullying_type'] == 1])\n",
    "    count_non_cyberbullying = len\\\n",
    "        (merged_df[merged_df['cyberbullying_type'] == 0])\n",
    "\n",
    "    print(f'Check here {count_cyberbullying}')\n",
    "    print(f'Check here {count_non_cyberbullying}')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNJ7n2jXbzwl"
   },
   "source": [
    "# Test and Train split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LQJjcE_Tb4JU",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check raw formspring_df:                                                 text  label\n",
      "0  what is your favorite song ? d i like too many...      0\n",
      "1                                 3 3 ? haha jk ! 33      0\n",
      "2  hey angel you duh sexy really ? ! ? ! thanks ?...      0\n",
      "3                                                         0\n",
      "4                                      meowww rawr ?      0\n",
      "Missing Values:\n",
      "tweet_text            0\n",
      "cyberbullying_type    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "<ipython-input-25-bb276f3ba1aa>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_text'] = df['tweet_text'].apply(clean_tweets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check cleaned formspring_df: Empty DataFrame\n",
      "Columns: [tweet_text, cyberbullying_type]\n",
      "Index: []\n",
      "Check raw cyberbullying tweet data:                                           tweet_text cyberbullying_type\n",
      "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
      "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
      "Missing Values:\n",
      "tweet_text            0\n",
      "cyberbullying_type    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "merged_df = driver()\n",
    "# extract the labels from the train data\n",
    "# y = train.label.values\n",
    "y = merged_df.cyberbullying_type.values\n",
    "\n",
    "# use 70% for the training and 30% for the test\n",
    "x_train, x_test, y_train, y_test = train_test_split(merged_df.tweet_text.values,\n",
    "                                                    y,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=1, \n",
    "                                                    test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EP0vIgrcdMSM"
   },
   "source": [
    "# Vectorize tweets using CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6M8mUI9n9fR"
   },
   "source": [
    "CountVectorizer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-5RsyYJBGPB"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "VSsrvD_nA0pQ",
    "outputId": "9a8267de-53b3-4415-ee0a-589184c2ca59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>channel</th>\n",
       "      <th>data</th>\n",
       "      <th>fun</th>\n",
       "      <th>import</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>my</th>\n",
       "      <th>passion</th>\n",
       "      <th>please</th>\n",
       "      <th>science</th>\n",
       "      <th>subscribe</th>\n",
       "      <th>this</th>\n",
       "      <th>to</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  channel  data  fun  import  is  it  my  passion  please  science  \\\n",
       "0    0        1     1    0       1   1   0   0        0       0        0   \n",
       "1    1        0     1    1       0   2   1   1        1       0        1   \n",
       "2    0        1     0    0       0   0   0   1        0       1        0   \n",
       "\n",
       "   subscribe  this  to  youtube  \n",
       "0          0     1   0        1  \n",
       "1          0     0   0        0  \n",
       "2          1     0   1        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"This is Import Data's Youtube channel\",\n",
    "             \"Data science is my passion and it is fun!\",\n",
    "             \"Please subscribe to my channel\"]\n",
    "\n",
    "# initializing the countvectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and make the document into a matrix\n",
    "document_term_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# check the result\n",
    "pd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reQP8v7Gb36g"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nv02BKQ-ee_m"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "it_BrO5qehpR"
   },
   "source": [
    "Apply Support Vetor Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEXBqGBGeeG6"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# classify using support vector classifier\n",
    "svm = svm.SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "prob = svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8SJ5l9iehjBT"
   },
   "source": [
    "# Accuracy score for SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lERS4fXwea7B",
    "outputId": "a1865915-6431-4097-d950-d7c6310fa74e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SVC is:  94.86912086766085 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy score for SVC is: \", accuracy_score(y_test, y_pred_svm) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Twitter Sentiment Analysis - Support Vector Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
